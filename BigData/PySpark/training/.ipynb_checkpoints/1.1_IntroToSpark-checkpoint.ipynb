{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History of Apache Spark\n",
    "[Link](https://www.analyticsvidhya.com/blog/2016/09/comprehensive-introduction-to-apache-spark-rdds-dataframes-using-pyspark/)\n",
    "\n",
    "Apache Spark was originally created at University of California, Berkeleyâ€™s AMPLab in 2009. The Spark code base was later donated to the Apache Software Foundation. Subsequently, it was open sourced in 2010. Spark is mostly written in Scala language. It has some code written in Java, Python and R. Apache Spark provides several APIs for programmers which include Java, Scala, R and Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release dates\n",
    "</p>\n",
    "<table class=\"wikitable\">\n",
    "\n",
    "<tbody><tr>\n",
    "<th>Version\n",
    "</th>\n",
    "<th>Original release date\n",
    "</th>\n",
    "<th>Latest version\n",
    "</th>\n",
    "<th>Release date\n",
    "</th></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"0.5\"><span style=\"display: none;\">Old version, no longer maintained:</span> 0.5\n",
    "</td>\n",
    "<td>2012-06-12\n",
    "</td>\n",
    "<td>0.5.1\n",
    "</td>\n",
    "<td>2012-10-07\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"0.6\"><span style=\"display: none;\">Old version, no longer maintained:</span> 0.6\n",
    "</td>\n",
    "<td>2012-10-14\n",
    "</td>\n",
    "<td>0.6.2\n",
    "</td>\n",
    "<td>2013-02-07\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"0.7\"><span style=\"display: none;\">Old version, no longer maintained:</span> 0.7\n",
    "</td>\n",
    "<td>2013-02-27\n",
    "</td>\n",
    "<td>0.7.3\n",
    "</td>\n",
    "<td>2013-07-16\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"0.8\"><span style=\"display: none;\">Old version, no longer maintained:</span> 0.8\n",
    "</td>\n",
    "<td>2013-09-25\n",
    "</td>\n",
    "<td>0.8.1\n",
    "</td>\n",
    "<td>2013-12-19\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"0.9\"><span style=\"display: none;\">Old version, no longer maintained:</span> 0.9\n",
    "</td>\n",
    "<td>2014-02-02\n",
    "</td>\n",
    "<td>0.9.2\n",
    "</td>\n",
    "<td>2014-07-23\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"1.0\"><span style=\"display: none;\">Old version, no longer maintained:</span> 1.0\n",
    "</td>\n",
    "<td>2014-05-26\n",
    "</td>\n",
    "<td>1.0.2\n",
    "</td>\n",
    "<td>2014-08-05\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"1.1\"><span style=\"display: none;\">Old version, no longer maintained:</span> 1.1\n",
    "</td>\n",
    "<td>2014-09-11\n",
    "</td>\n",
    "<td>1.1.1\n",
    "</td>\n",
    "<td>2014-11-26\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"1.2\"><span style=\"display: none;\">Old version, no longer maintained:</span> 1.2\n",
    "</td>\n",
    "<td>2014-12-18\n",
    "</td>\n",
    "<td>1.2.2\n",
    "</td>\n",
    "<td>2015-04-17\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"1.3\"><span style=\"display: none;\">Old version, no longer maintained:</span> 1.3\n",
    "</td>\n",
    "<td>2015-03-13\n",
    "</td>\n",
    "<td>1.3.1\n",
    "</td>\n",
    "<td>2015-04-17\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"1.4\"><span style=\"display: none;\">Old version, no longer maintained:</span> 1.4\n",
    "</td>\n",
    "<td>2015-06-11\n",
    "</td>\n",
    "<td>1.4.1\n",
    "</td>\n",
    "<td>2015-07-15\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"1.5\"><span style=\"display: none;\">Old version, no longer maintained:</span> 1.5\n",
    "</td>\n",
    "<td>2015-09-09\n",
    "</td>\n",
    "<td>1.5.2\n",
    "</td>\n",
    "<td>2015-11-09\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"1.6\"><span style=\"display: none;\">Old version, no longer maintained:</span> 1.6\n",
    "</td>\n",
    "<td>2016-01-04\n",
    "</td>\n",
    "<td>1.6.3\n",
    "</td>\n",
    "<td>2016-11-07\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"2.0\"><span style=\"display: none;\">Old version, no longer maintained:</span> 2.0\n",
    "</td>\n",
    "<td>2016-07-26\n",
    "</td>\n",
    "<td>2.0.2\n",
    "</td>\n",
    "<td>2016-11-14\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"2.1\"><span style=\"display: none;\">Old version, no longer maintained:</span> 2.1\n",
    "</td>\n",
    "<td>2016-12-28\n",
    "</td>\n",
    "<td>2.1.3\n",
    "</td>\n",
    "<td>2018-06-26\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td style=\"background-color: #FDB3AB;\" title=\"Old version, no longer maintained\" data-sort-value=\"2.2\"><span style=\"display: none;\">Old version, no longer maintained:</span> 2.2\n",
    "</td>\n",
    "<td>2017-07-11\n",
    "</td>\n",
    "<td>2.2.3\n",
    "</td>\n",
    "<td>2019-01-11\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td class=\"templateVersion co\" style=\"background-color: #FEF8C6;\" title=\"Older version, yet still maintained\" data-sort-value=\"2.3\"><span style=\"display: none;\">Older version, yet still maintained:</span> 2.3\n",
    "</td>\n",
    "<td>2018-02-28\n",
    "</td>\n",
    "<td>2.3.4\n",
    "</td>\n",
    "<td>2019-09-09\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td class=\"templateVersion co\" style=\"background-color: #FEF8C6;\" title=\"Older version, yet still maintained\" data-sort-value=\"2.4\"><span style=\"display: none;\">Older version, yet still maintained:</span> 2.4\n",
    "</td>\n",
    "<td>2018-11-02\n",
    "</td>\n",
    "<td>2.4.6\n",
    "</td>\n",
    "<td>2020-06-05<sup id=\"cite_ref-37\" class=\"reference\"></sup>\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td class=\"templateVersion c\" style=\"background-color: #D4F4B4;\" title=\"Current stable version\" data-sort-value=\"3.0\"><span style=\"display: none;\">Current stable version:</span> <b>3.0</b>\n",
    "</td>\n",
    "<td>2020-06-18\n",
    "</td>\n",
    "<td>3.0.0\n",
    "</td>\n",
    "<td>2020-06-18<sup id=\"cite_ref-38\" class=\"reference\"></sup>\n",
    "</td></tr>\n",
    "<tr>\n",
    "<td colspan=\"4\"><small><div class=\"templateVersion l\" style=\"margin-left: -1em;\"><div style=\"float: left; margin-left: 1em;\"><span style=\"white-space: nowrap;\"><b>Legend:</b></span></div><div style=\"float: left; margin-left: 1em;\"><span style=\"border-left: 1.2em solid #FDB3AB; padding-left: 0.3em; white-space: nowrap;\" title=\"Old version, no longer maintained\">Old version</span></div><div style=\"float: left; margin-left: 1em;\"><span style=\"border-left: 1.2em solid #FEF8C6; padding-left: 0.3em; white-space: nowrap;\" title=\"An older version, yet still maintained\">Older version, still maintained</span></div><div style=\"float: left; margin-left: 1em;\"><span style=\"border-left: 1.2em solid #D4F4B4; padding-left: 0.3em; white-space: nowrap;\" title=\"Latest stable version\"><b>Latest version</b></span></div><div style=\"float: left; margin-left: 1em;\"><span style=\"border-left: 1.2em solid #FED1A0; padding-left: 0.3em; white-space: nowrap;\" title=\"Latest preview of a future release\">Latest preview version</span></div><div style=\"float: left; margin-left: 1em; display: none;\"><span style=\"border-left: 1.2em solid #C1E6F5; padding-left: 0.3em; white-space: nowrap;\" title=\"A future release\">Future release</span></div><div style=\"clear: left;\"></div></div></small>\n",
    "</td></tr></tbody></table>\n",
    "\n",
    "<p style=\"font-size:1em; color:green; font-family:'Courier New'; text-align: center\">source: https://en.wikipedia.org/wiki/Apache_Spark</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkContext vs SparkSession\n",
    "* **sparkContext**: In older version of Spark there was different contexts that was entrypoints to the different api (core api, sql context for the spark-sql api, streaming context for the Dstream api etc...) this was source of confusion for the developer\n",
    "\n",
    "\n",
    "* **sparkSession**: in the most recent versions of spark (<font color=green>**SPARK 2.0.0 onwards:**</font>) there is only one entrypoint: for all the APIs. In order to use APIs of SQL, HIVE, and Streaming, no need to create separate contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDDs vs DataFrames and Datasets\n",
    "[Source](https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html)\n",
    "\n",
    "Released in [verion 2.0](https://spark.apache.org/releases/spark-release-2-0-0.html) where Datasets is just an alias for dataFrames for Scala/Java (Python don't have Datasets APIs).\n",
    "\n",
    "### Resilient Distributed Dataset (RDD)\n",
    "\n",
    "At the core, an RDD is an immutable distributed collection of elements of your data, partitioned across nodes in your cluster that can be operated in parallel with a low-level API that offers transformations and actions.\n",
    "\n",
    "#### When to use RDDs?\n",
    "* you want low-level transformation and actions and control on your dataset;\n",
    "* your data is unstructured, such as media streams or streams of text; (so ???)\n",
    "* you want to manipulate your data with functional programming constructs than domain specific expressions; (???)\n",
    "* you donâ€™t care about imposing a schema, such as columnar format, while processing or accessing data attributes by name or column; (???)\n",
    "* you can forgo some optimization and performance benefits available with DataFrames and Datasets for structured and semi-structured data. (*only in case of small data, you don't want to forgot about optimizations in big data !!*)\n",
    "\n",
    "#### What happens to RDDs in Apache Spark 2.0?\n",
    "Is easy to move between DataFrame or Dataset and RDDs at willâ€”by simple API method callsâ€”and DataFrames and Datasets are built on top of RDDs.\n",
    "\n",
    "Are RDDs being relegated as second class citizens? Are they being deprecated?\n",
    "\n",
    "The answer is a resounding ~~NO!~~ YES!\n",
    "\n",
    "Why ? Well, we'll see that we can do almost the same with data frames, are simpler and they are optimized !!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "* Like an RDD, a DataFrame is an immutable distributed collection of data. \n",
    "* Unlike an RDD, data is organized into named columns, like a table in a relational database. \n",
    "\n",
    "Designed to make large data sets processing even easier, DataFrame allows developers to impose a structure onto a distributed collection of data; it provides a domain specific language API to manipulate your distributed data; and makes Spark accessible to a wider audience\n",
    "\n",
    "*Obs: Since I am focous in Python I'm not going to describe datasets.*\n",
    "\n",
    "### Some advantages\n",
    "\n",
    "* **domain specific operations**: DF introduces rich semantics and an easy set of domain specific operations that can be expressed as high-level constructs. For example, itâ€™s much simpler to perform *agg, select, sum, avg, map, filter, or groupBy* than using RDD rowsâ€™ data fields.\n",
    "\n",
    "* **Performance and Optimization**: \n",
    " + 1) DataFrame and Dataset APIs are built on top of the Spark SQL engine, it uses *Catalyst to generate an optimized logical and physical query plan*. Across R, Java, Scala, or Python DataFrame/Dataset APIs, all relation type queries undergo the same code optimizer, providing the space and speed efficiency.\n",
    " \n",
    " + 2) since Spark as a compiler understands your Dataset type JVM object, it maps your type-specific JVM object to Tungstenâ€™s internal memory representation using Encoders. As a result, Tungsten Encoders can efficiently serialize/deserialize JVM objects as well as generate compact bytecode that can execute at superior speeds.\n",
    "???: Not sure if the above applies to Python DataFrames too - [read more about tungsten](https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html)\n",
    "\n",
    "### When should I use DataFrames or Datasets?\n",
    "* If you want rich semantics, high-level abstractions, and domain specific APIs, use DataFrame or Dataset.\n",
    "* If your processing demands high-level expressions, filters, maps, aggregation, averages, sum, SQL queries, columnar access and use of lambda functions on semi-structured data, use DataFrame or Dataset.\n",
    "* If you want higher degree of type-safety at compile time, want typed JVM objects, take advantage of Catalyst optimization, and benefit from Tungstenâ€™s efficient code generation, use Dataset.\n",
    "* ~~If you want unification and simplification of APIs across Spark Libraries, use DataFrame or Dataset.~~\n",
    "* If you are a R user, use DataFrames.\n",
    "* If you are a Python user, use DataFrames and resort back to RDDs if you need more control.\n",
    "\n",
    "Note that you can always seamlessly interoperate or convert from DataFrame and/or Dataset to an RDD, by simple method call .rdd. For instance,\n",
    "\n",
    "LOOK FOR SOME REAL EXAMPLES:\n",
    "```python\n",
    "#/ select specific fields from the Dataset, apply a predicate\n",
    "#// using the where() method, convert to an RDD, and show first 10\n",
    "#// RDD rows\n",
    "deviceEventsDS = ds.select($\"device_name\", $\"cca3\", $\"c02_level\").where($\"c02_level\" > 1300)\n",
    "#// convert to RDDs and take the first 10 rows\n",
    "eventsRDD = deviceEventsDS.rdd.take(10)\n",
    "```\n",
    "\n",
    "Eventhough its simplicity .. avoid above practicies as much as possible ! Converting DF to RDDs and viceversa could take a long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalyst Optimizer\n",
    "[source](https://databricks.com/glossary/catalyst-optimizer)\n",
    "\n",
    "At the core of Spark SQL is the Catalyst optimizer. \n",
    "Catalyst is based on functional programming constructs in Scala and designed with these key two purposes:\n",
    "* Easily add new optimization techniques and features to Spark SQL\n",
    "* Enable external developers to extend the optimizer.\n",
    "\n",
    "![Query Plan](img/query_plan.png \"Query Plan\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
